---
title: "LeetCode: Binary Search"
description: "binary search"
image: "../../public/Notes/binary-search.png"
publishedAt: "2025-07-02"
updatedAt: "2025-07-02"
author: "jonathancamberos"
isPublished: true
tags:
- data structures and algorithms
---

## Binary Search Intro:

Leetcode problems with elegant solutions using binary search. 

### What is Binary Search
Binary Search is a divide and conquer algorithm for searching 
sorted lists or ranges effectively.

It works by creating a middle value, comparing middle value to the target
or evaluating a condition, and halving the search space 
based on that comparison.

### Why Use Binary Search
Binary search reduces the search space by half on each iteration.

|  Technique  | Time Complexity | Space Complexity | 
| -------- | --------------- | ---------------- | 
| Linear Search | O(n) | O(1) |
| Binary Search (Recursive) | O(log n) | O(log n) |
| Binary Search (Iterative) | O(log n) | O(1) |

### Target Binary Search
Used to search for a specific value or index.

```python
    def binary_search(nums, target):
        left, right = 0, len(nums) - 1

        # Note 1:
        # Target Binary Search: uses '<='
        while left <= right:
            mid = (left + right) // 2

            # Note 2:
            # 3 parts during iteration
            # target check, remove left half, remove right half
            if nums[mid] == target:
                return mid
            elif nums[mid] < target:
                left = mid + 1
            else:
                right = mid - 1

        # Note 3:
        # Exit: left > right triggers ends
        # Return value if not found
        return -1 
```

### Monotonic Optimization Min/Max Binary Search
Used to find the smallest or largest value that satisfies a condition.

1. Find the min element greater than or equal to the target:

In ceiling search, the goal is to locate the minimal number in a sorted 
```python
    def find_min_valid_value():
        left, right = 0, N-1

        # Note 1:
        # Optimization Binary Search: uses '<'
        while left < right:
            mid = (left + right) // 2

            # Note 2:
            # Check if condition is satisfied
            # If so, include mid with left or right half
            if condition(mid):
                # or left = mid, depending on which half we are checking
                right = mid      
            else:
                # or right = mid + 1, depending on which half we are removing
                left = mid + 1 

        # Note: 3
        # Exit: left == right, triggers the exit
        # we have found the optimized solution

        # or right
        return left 
```

### Optimization Ceiling and Floor Style Binary Search 
Variant of Optimization Binary Search:

The rule is that we can search directly for ceilings, 
but not for floors.

You can search directly for the ceiling (smallest element >= target)
with binary search because the loop naturally stops at that boundary.
```python
    def find_ceiling(nums, target):
        left, right = 0, len(nums)

        # Loop condition: left < right
        while left < right:
            mid = (left + right) // 2
            
            # If mid element is less than target,
            # the ceiling must be to the right of mid (exclude mid)
            if nums[mid] < target:
                left = mid + 1
            else:
                # nums[mid] >= target, potential ceiling candidate
                # Keep mid in search space by moving right boundary to mid
                right = mid
        
        # At the end, left == right, points to the smallest element >= target if exists
        # If left == len(nums), no ceiling found
        if left == len(nums):
            return None
        return nums[left]
```

You cannot search directly for the floor (largest element < = target)
with binary search
```python
def find_floor_wrong(nums, target):
    left, right = 0, len(nums)

    # Loop condition: left < right
    while left < right:
        mid = (left + right) // 2

        # Attempt: 
        # mid element <= target:
        # move left boundary up to mid (include mid)
        if nums[mid] <= target:
            
            # PROBLEM: 
            # left might not move forward when left == mid, causing infinite loop
            left = mid 
            
        else:
            # mid element > target:
            # move right boundary down (exclude mid)
            right = mid

    # When loop ends, left == right, but it may not point to floor directly
    # Without shifting left or checking bounds, this is unreliable
    if left == 0 and nums[left] > target:
        return None
    return nums[left]
```

### Understanding Optimization Search: Min vs Max
In optimization style binary search, we're not finding a specific value,
but rather are finding the smallest or largest values that satisfies a condition.

1. Finding the Minimum Valid Value 
```python
    if condition(mid):
        right = mid        # mid might be the answer, keep it
    else:
        left = mid + 1     # mid is invalid, discard it
```
2. Finding the Maximum Valid Value
```python
    if condition(mid):
        left = mid         # mid might be the answer, keep it
    else:
        right = mid - 1    # mid is invalid, discard it`
```

### Why Binary Search Can Find < or > but Not < or > equal to 
Binary Search splits the space at mid and decides whether
to include or exclude it.

This means it works best with strict boundaries.

Its easy to shrink towards a point where the transition happens
on < or >.

However, it struggles with ambiguous boundaries like < and > or equal to.
As you don't know which direction to move in.

Ex: first element < or equal to target
```python
# When:
    arr[mid] == target

# Should you go left or right?
# If you go right, you might miss an earlier match
# If you go left, you might go too far and miss it entirely
# If you don't reduce the search space and include mid, the loop may never terminate 
```

So binary search prefers to work with 
< for upper bound, > for lower bound.
And shift answer manually to get < and > or equal to.

### Insight on Pointer Updates
A basic but easily overlooked principle in binary search is that 
the search space must shrink with every iteration.

This ensures the algorithm makes progress and terminates.

In target binary search:

We are looking for a specific index or value. 
After comparing mid,  we either return mid as we have found the target, 
or search the left or right subspace while excluding mid 
as mid has already been checked.

In target binary search, we might hit the target before 
the pointers trigger termination

In optimization binary search:

We are looking for a min/max valid value, not just looking for a specific value.
In this case after comparing mid, search the left or right subspace
and include mid as mid could be the potential solution, until our pointers
hit each other and we have found our optimal solution. 

In optimization binary search, the trigger will be that the pointers
will equal each other every time, returning the optimal solution.

### Limitation with duplicates
In most standard binary search problems, duplicates do not interfere with
correctness or efficiency as long as:
1. The array is fully sorted
2. We're doing a target lookup or numeric optimization
3. No structural transformations like rotation or flattening is applied that would affect the sorted order

Some problems depend on structure or ordering of elements (e.g., rotated arrays).
In these cases, duplicates introduce ambiguity that binary search cannot resolve cleanly.

Ex: without duplicates
```python
nums = [4, 5, 6, 7, 0, 1, 2]

def find_min_no_duplicates(nums):
    left, right = 0, len(nums) - 1
    
    while left < right:
        mid = (left + right) // 2
        
        if nums[mid] > nums[right]:
            # Min must be in the right half (excluding mid)
            left = mid + 1
        else:
            # Min is at mid or in the left half
            right = mid
            
    return nums[left]
```

Ex: with duplicates
```python
nums = [2, 2, 2, 0, 1, 2]

def find_min_with_duplicates(nums):
    left, right = 0, len(nums) - 1

    while left < right:
        mid = (left + right) // 2
        
        if nums[mid] > nums[right]:
            left = mid + 1
        elif nums[mid] < nums[right]:
            right = mid
        else:
            # nums[mid] == nums[right], can't determine side, shrink range
            right -= 1

    return nums[left]
```


### Binary Search Application: Target Binary Search
Using Binary Search to locate the position of a target element 
in a sorted list by repeatedly dividing the search interval in half.

Ex: Searching for a target number in a sorted array.
```python
    def binarySearch(nums, target):
    left, right = 0, len(nums) - 1

    while left <= right:
        mid = (left + right) // 2

        if nums[mid] == target:
            return mid  # Target found
        elif nums[mid] < target:
            left = mid + 1  # Search right half
        else:
            right = mid - 1  # Search left half

    return -1  # Target not found
```

### Binary Search Application: Multiple Layers Binary Search
Applying binary search in multiple stages or layers, typically to 
first narrow down a substructure (i.e., row, segment, or time range), 
and then again within that substructure

This approach is useful when data is structured in nested sorted layers.

Ex: Searching for a target in a sorted 2D matrix
```python
    def searchMatrix(matrix: List[List[int]], target: int) -> bool:
        if not matrix or not matrix[0]:
            return False

        rows, cols = len(matrix), len(matrix[0])

        # First layer: Binary search over rows to find candidate row
        top, bottom = 0, rows - 1
        while top <= bottom:
            mid_row = (top + bottom) // 2
            if matrix[mid_row][0] <= target <= matrix[mid_row][-1]:
                break
            elif matrix[mid_row][0] > target:
                bottom = mid_row - 1
            else:
                top = mid_row + 1
        else:
            return False  # Target is outside all row ranges

        # Second layer: Binary search within the found row
        row = mid_row
        left, right = 0, cols - 1
        while left <= right:
            mid_col = (left + right) // 2
            if matrix[row][mid_col] == target:
                return True
            elif matrix[row][mid_col] < target:
                left = mid_col + 1
            else:
                right = mid_col - 1

        return False
```

### Binary Search Application: Optimization Search Min Max Binary Search 
Using binary search to find the smallest or largest valid value 
that satisfies a given constraint (e.g., minimum speed, minimum time, maximum capacity)

Searches over a numeric range, not for a target, 
and typically uses while left < right (left == right, as a trigger)
to fin the min or max boundary.

Ex: Find the minimum eating speed to finish all bananas within h hours
```python
    def minEatingSpeed(piles: List[int], h: int) -> int:
        def hours_needed(speed):
            return sum((pile + speed - 1) // speed for pile in piles)  # ceil

        left, right = 1, max(piles)

        # Optimization Search
        while left < right:
            mid = (left + right) // 2

            # Try slower (minimization)
            if hours_needed(mid) <= h:
                right = mid  
            
            # Need faster
            else:
                left = mid + 1 

        # Note:
        # there is no case where left > right breaks the loop,
        # because the condition is < and not <=,
        # so trigger will always be:
        # left == right
        
        # Smallest k that works
        return left  
```

### Binary Search Application: Condition Adapted Binary Search
Adapting search conditions of binary search to account for special
problem parameters or constraints (e.g., rotated array, duplicates, bounded search).

Covers problems where binary search is applied, but the standard algorithm
is modified.

Ex: Finding the minimum element in a rotated sorted array
```python
    def findMin(nums: List[int]) -> int:
        left, right = 0, len(nums) - 1

        # If array is not rotated (fully sorted ascending)
        if nums[left] < nums[right]:
            return nums[left]

        # Modified binary search with parameter-based decision
        while left < right:
            mid = (left + right) // 2
            
            # Decision based on comparing mid and right elements
            if nums[mid] > nums[right]:
                left = mid + 1
            else:
                right = mid

        # left == right points to minimum element
        return nums[left]
```

### Binary Search Application: Upper Ceiling or Lower Floor Trick Based on Target Binary Search
Binary search cannot directly find the largest element less than or equal to a target
(or similarly find the smallest elements greater than or equal to a target)
in one step.

Instead we search for the first element greater than the target and then simply 
shift one position left to get the largest element less than or equal. 

Ex: Find the first element less than or equal to target
```python
    def largest_leq_shift(nums, target):
        left, right = 0, len(nums)  # half-open interval [left, right)

        while left < right:
            mid = (left + right) // 2
            if nums[mid] <= target:
                left = mid + 1  # move right since mid less to target
            else:
                right = mid     # mid > target, shrink right side

        # left is now the index of first element > target
        # so the answer is at left - 1 (if valid)
        return nums[left - 1] if left > 0 else ""
```

## 704. Binary Search ::2:: - Easy

Topics:  Array, Binary Search

### Intro
> Given an array of integers nums which is sorted in ascending order, 
> and an integer target, write a function to search target in nums.
> If target exists, then return its index. Otherwise, return -1.
> You must write an algorithm with O(log n) runtime complexity.

|  Example Input           | Output |  
| ---------------- | ------ | 
| nums = [-1,0,3,5,9,12] target = 9 | 4 |
| nums = [-1,0,3,5,9,12], target = 2 | -1  |  
 
Constraints:

1 &leq; nums.length &leq; 10<sup>4</sup>

-10<sup>4</sup> &le; nums[i], target &le; 10<sup>4</sup>

All the integers in nums are unique

nums is sorted in ascending order


### Abstraction
Given a sorted list of elements, find the target

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
|  |  |  |  |  |


| Bug | Error |
| --- | ----- |
|  |  | 


### Brute Force: (iterative)
```python
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |


### Find the Bug: Missing return value
```python
    def search(self, nums: List[int], target: int) -> int:
        
        def helper(left, right):
            
            # base case: target not found
            if left > right:
                return -1

            mid = (left+right)//2

            # base case target found
            if nums[mid] == target:
                return mid

            # search right
            elif nums[mid] < target:

                # INCORRECT:
                # no return value
                # Instead:
                # return helper(mid+1, right)
                helper(mid+1, right)
            
            # search left
            else:
                # INCORRECT:
                # no return value
                # Instead: 
                # return helper(left, mid-1)
                helper(left, mid-1)

        res = helper(0, len(nums)-1)
        return res
```

### Solution 1: Recursive Binary Search - Binary Search/Searching
```python
    def search(self, nums: List[int], target: int) -> int:
        
        # Note:
        # Recursive binary search calls itself with smaller range,
        # and leads to call stack of O(log n)

        def helper(left, right):
            # base case: target not found
            if left > right:
                return -1

            mid = (left + right) // 2

            # base case: target found
            if nums[mid] == target:
                return mid

            # search right side
            elif nums[mid] < target:
                return helper(mid + 1, right)
            # search left side
            else:
                return helper(left, mid - 1)

        # time complexity: each call halves the search space O(log n)
        # space complexity: call stack grows with depth O(log n)
        result = helper(0, len(nums) - 1)

        # overall: time complexity O(log n)
        # overall: space complexity O(log n)
        return result
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Variable assigning | O(1) | O(1) | Initializing variables in constant O(1) | No additional memory allocation for constant variables O(1) |
| Recursive Binary Search | O(log n) | O(log n) | Search space is halved on each recursive call O(log n) | Call stack grows to depth O(log n) |
| Overall | O(log n) | O(log n) | Binary search over sorted list dominates, leading to O(log n) | Stack memory used for recursive calls dominates, leading to O(log n) |

### Solution 2: Iterative Binary Search - Binary Search/Searching
```python
    def search(self, nums: List[int], target: int) -> int:
        
        # Note:
        # simple binary search

        # space complexity: simple variables in constant O(1)
        left, right = 0, len(nums)-1

        # target binary search with '<='
        # time complexity: split search area per iteration O(log n)
        # space complexity: iterative search, no call stack, O(1)
        while left <= right:
            
            mid = (left+right)//2
            
            # found target, return
            if nums[mid] == target:
                return mid

            # search right side of subsection
            elif nums[mid] < target:
                left = mid + 1
            
            # search left side of subsection
            else: 
                right = mid - 1

        # overall: time complexity O(log n)
        # overall: space complexity O(1)
        return -1
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Variable assigning | O(1) | O(1) | Initializing variables in constant O(1) | No additional memory allocation for constant variables O(1) |
| Iterative Binary Search | O(log n) | O(1) | Loop halves the search space on each iteration O(log n) | No additional memory allocation beyond loop variables O(1) |
| Overall | O(log n) | O(1) | Binary search over sorted array O(log n) | No additional memory allocation O(1) |


## 74. Search a 2D Matrix ::2:: - Medium

Topics:  Array, Binary Search, Matrix

### Intro
> You are given an m x n integer matrix matrix with the following two properties:
> Each row is sorted in non-decreasing order.
> The first integer of each row is greater than the last integer of the previous row.
> Given an integer target, return true if target is in matrix or false otherwise.
> You must write a solution in O(log(m * n)) time complexity.

|  Example Input   | Output |  
| ---------------- | ------ | 
| matrix = [[1,3,5,7],[10,11,16,20],[23,30,34,60]], target = 3 | true |
| matrix = [[1,3,5,7],[10,11,16,20],[23,30,34,60]], target = 13 | false  |  
 
Constraints:

m == matrix.length
n == matrix[i].length

1 &leq; m, n &leq; 100

-10<sup>4</sup> &le; matrix[i][j], target &le; 10<sup>4</sup>

### Abstraction
Given a sorted matrix, check if target is in matrix

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
|  |  |  |  |  |

| Bug | Error |
| --- | ----- |
|  |  | 

### Brute Force: 
```python
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |

### Find the Bug: Did not follow Binary Search 
```python
```

### Find the Bug: Forgot to break
```python
    def searchMatrix(self, matrix: List[List[int]], target: int) -> bool:
        
        if len(matrix) == 0 or len(matrix[0]) == 0:
            return False

        rows, cols = len(matrix), len(matrix[0])
        top, bottom = 0, rows-1
        rowCand = 0

        # first binary search
        while top <= bottom:

            mid = (top+bottom)//2

            if matrix[mid][0] <= target <= matrix[mid][-1]:
                # INCORRECT:
                # never exiting the while loop
                # Instead:
                # break
                rowCand = mid

            elif matrix[mid][-1] < target:
                top = mid+1
            else:
                bottom = mid-1
        
        else:
            return False

        left, right = 0, len(matrix[rowCand])-1

        while left <= right:

            mid = (left+right)//2
            val = matrix[rowCand][mid]

            if val == target:
                return True

            elif val < target:
                left = mid + 1
            
            else: 
                right = mid - 1
        else:
            return False
```

### Solution 1: Flattened Matrix by Index To Coordinates Binary Search - Binary Search/Searching
```python
    def searchMatrix(self, matrix: List[List[int]], target: int) -> bool:
        
        # Note:
        # Treats the 2D matrix as a sorted 1D array by flattening indices.
        # Uses binary search on the 1D index space,
        # and converts indices to 2D coordinates with the helper function.
        # This approach runs in O(log(m * n)) time and O(1) space.
        
        # diagram:
        # matrix = [
        # col 0   1   2
        #   [ 1,  3,  5],   # row 0
        #   [ 7,  9, 11],   # row 1
        #   [13, 15, 17],   # row 2
        # ] 

        # Helper: Convert 1D index to 2D matrix coordinates (row, col)
        # index 4 -> (4//3, 4%3) -> (1, 1) = 9
        # index 5 -> (5//3, 5%3) -> (1, 2) = 11
        def index_to_coords(index, cols) -> tuple[int, int]:
            row = index // cols
            col = index % cols
            return (row, col)

        # check if 0 rows or 0 columns
        if not matrix or not matrix[0]:
            return False

        # initialize rows and columns
        rows, cols = len(matrix), len(matrix[0])

        # calculate 2D matrix representation
        left, right = 0, rows * cols - 1

        # binary target search with '<='
        # time complexity: binary search on flattened 2D matrix [0,(m*n)-1] O(log(m*n))
        while left <= right:
            
            # getting relative 2D mid index, converting, and grabbing value from matrix
            mid = (left + right) // 2
            (row, col) = index_to_coords(mid, cols)
            mid_value = matrix[row][col]

            # check if target
            if mid_value == target:
                return True
            
            # check right space
            elif mid_value < target:
                left = mid + 1
            
            # check left space
            else:
                right = mid - 1

        # target does not exist

        # overall time complexity: O(log (m * n))
        # overall space complexity: O(1)
        return False
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Binary search 1D index | O(log (m*n)) = O(log(m) + log(n)) | O(1) | Binary search over full flattened matrix treated as 1D O(log (m*n)) | No additional memory allocation |


### Solution 2: Two Phase Binary Search over Row Ranges and Binary Search in Row Candidate - Binary Search/Searching
```python
    def searchMatrix(self, matrix: List[List[int]], target: int) -> bool:
        
        # Note:
        # Performs two separate binary searches:
        # 1. Binary Search over rows to locate potential row
        # 2. Binary Search within that row to find the target
        
        # diagram:
        # matrix = [
        # col 0   1   2
        #   [ 1,  3,  5],   # row 0
        #   [ 7,  9, 11],   # row 1
        #   [13, 15, 17],   # row 2
        # ]

        # check if 0 rows or 0 columns
        if not matrix or not matrix[0]:
            return False

        # initialize rows and columns
        rows, cols = len(matrix), len(matrix[0])

        # First layer: 
        # Binary search over row range to find candidate row
        
        # top and bottom rows (refer to diagram)
        top, bottom = 0, rows - 1

        # binary target search with '<='
        # time complexity: binary search over range rows for n rows O(log n)
        while top <= bottom:

            # grab mid row
            mid_row = (top + bottom) // 2

            # check if target is potentially within row
            if matrix[mid_row][0] <= target <= matrix[mid_row][-1]:
                break

            # Note:
            # top is 0, bottom is n-1,
            # so update cases accordingly

            # search above rows (lower rows, see diagram)
            elif matrix[mid_row][0] > target:
                bottom = mid_row - 1

            # search below rows (upper rows, see diagram)
            else:
                top = mid_row + 1

        # Target is outside all row ranges
        else:
            return False
            
        # Second layer: 
        # Found row candidate, binary search within row to check if target exists
        row = mid_row

        # outer boundaries
        left, right = 0, cols - 1

        # binary target search with '<='
        # time complexity: binary search in row for m columns O(log m)
        while left <= right:

            # mid of row
            mid_col = (left + right) // 2
            
            # target found
            if matrix[row][mid_col] == target:
                return True
            
            # search right of row
            elif matrix[row][mid_col] < target:
                left = mid_col + 1
            
            # search left of row
            else:
                right = mid_col - 1

        # overall: time complexity O(log (m * n)) 
        # overall: space complexity O(1)
        return False
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Binary search rows | O(log m) | O(1) | Binary search across m rows O(log m) | No additional memory allocation for binary search O(1) |
| Binary search columns | O(log n) | O(1) | Binary search across column of n length O(log n) | No additional memory allocation for binary search O(1) |
| Overall | O(log m + log n) = O(log (m*n)) | O(1) | Sum of two binary searches dominates, leading to O(log m + log n) | No additional memory allocation, leading to O(1)  |


## 875. Koko Eating Bananas ::2:: - Medium

Topics:  Array, Binary Search, Network Packet Routing

### Intro
> Koko loves to eat bananas. There are n piles of bananas, the ith pile has piles[i] bananas.
> The guards have gone and will come back in h hours.
> Koko can decide her bananas-per-hour eating speed of k.
> Each hour, she chooses some pile of bananas and eats k bananas from that pile.
> If the pile has less than k bananas, she eats all of them instead and will not eat any more bananas during this hour.
> Koko likes to eat slowly but still wants to finish eating all the bananas before the guards return.
> Return the minimum integer k such that she can eat all the bananas within h hours.

|  Example Input   | Output |  
| ---------------- | ------ | 
| piles = [3,6,7,11], h = 8 | 4 |
| piles = [30,11,23,4,20], h = 5 | 30 |  
| piles = [30,11,23,4,20], h = 6 | 23 |
 
Constraints:

1 &leq; piles.length &leq; 10<sup>4</sup>

piles.length &leq; h &leq; 10<sup>9</sup>

1 &leq; piles[i] &leq; 10<sup>9</sup>

### Abstraction
Find minimum bananas per hour so that all are eaten in time.

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
|  |  |  |  |  |

| Bug | Error |
| --- | ----- |
|  |  | 

### Brute Force: (iterative)
```python
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |


### Find the Bug: (iterating element-wise)
```python
```

### Solution 1: Binary Search - Binary Search/Optimization Search Min Max
```python
    import math

    def minEatingSpeed(self, piles: List[int], h: int) -> int:
        
        # Note:
        # Find minimum int k such that Koko can eat all bananas within h hours
        # Number of hours decreases monotonically as k increases, binary search is optimal
        # For each speed k, we calculate how many hours it would take
        # Outer binary search over k, inner calculation per pile
        
        # Minimum speed: 1 banana per hour        
        # Maximum speed: largest pile size, anything above the largest pile size is a waste
        left, right = 1, max(piles)
        
        # total hours needed to eat all piles at speed k
        # time complexity: iterate over n piles O(n)
        def hours_needed(speed):
            total_hours = 0
            for pile in piles:

                # Koko has fixed eating speed k
                # if she has pile bananas and eats at k bananas/hr
                # she will she ciel(pile/k) becuase she won't stop in the middle of an hour
                # if there are 3 bananas with eating speed 5, it will still take a full hour
                total_hours += math.ceil(pile / speed)
            
            return total_hours
        
        # binary optimization search with '<' for min k
        # time complexity: binary search over k speeds where k is the max(piles) O(log(max(piles)))
        while left < right:

            mid = (left + right) // 2
            
            # hours needed at speed k = mid
            required_hours = hours_needed(mid)
            
            # Notice: 
            # we are not finding a target,
            # but instead are finding a minimum k
            # so we do not need to check for a target

            # current time works
            # try shorter times, including current mid time (lower k)
            if required_hours <= h:
                right = mid
            
            # current time does not work
            # try longer times, not including current mid time (higher k)
            else:
                left = mid + 1
        
        # left == right is the min k

        # overall: time complexity O(n * log(max(piles)))
        # overall: space complexity O(1)
        return left
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Outer Binary Search | O(log(max(piles))) | O(1) | Binary search over range of possible speeds from 1 to max files size O(log(max(piles))) | No additional memory allocation for binary search O(1) |
| Hours calculation | O(n) | O(1) | Iterate over all piles to calculate if piles are eaten O(n) | No additional memory allocation for calculation O(1) |
| Overall | O(n * log(max(piles))) | O(1) | Binary search over range alongside hours calculation per candidate dominates, leading to O(n * log(max(piles))) | No additional memory allocation O(1) |

### Solution 2: Networking Router Analogy, Greedy Heuristic Guided Monotonic Search with Exponential Speed Doubling - Binary Search/Optimization Search Min Max
```python
    def minEatingSpeed(self, piles: List[int], h: int) -> int:

        # Network Router Analogy:
        # Think of Koko as a router, banana piles as incoming data packets,
        # and h as the deadline (max allowable latency in seconds).

        # Note:
        # Greedy Start:
        # Start speed k from a heuristic lower bound.

        # Note:
        # Greedy search: 
        # If total eating time exceeds h by a large margin:
        # speeds up eating speed k aggressively (double the speed).

        # If total eating time is close to h:
        # increment eating speed k slowly by 1 util valid minimum k is found.

        # Pros:
        # Can outperform binary search in practice for some inputs
        
        # Cons: 
        # Lacks worst case guarantees, (binary search guarantees O(log n) worst case)

        # Note
        # Heuristics:
        # 3 heuristic lower bound k starting speed close to min eating speed:
        # 1. Total bananas: Throughput 
        # 2. Smallest Pile: Fair Time Sharing
        # 3. Largest Pile: Bottleneck detection

        # Note:
        # Good Heuristics by Constraints:
        # Must be lower bounds, must never overestimate
        # Close to the real answer, to minimize search time
        # Must be computable in O(n) time, to be scalable
        # Compete between different system perspectives
        
        # Three represent system level perspectives:
        # 1. Global Bandwidth
        # 2. Fair time allocation
        # 3. Single queue congestion

        # Other discarded Heuristics:
        
        # Discard 1. Average between piles:
        # Does not factor time constraint, assumes infinite time

        # Discard 2. Max pile divided over h hours
        # high router k speed wasted on smaller piles

        # Heuristics Take away :

        # A good heuristic must take into account:
        # Data size (bananas)
        # Time Constrain (h)

        # And follow:
        # True lower bound
        # Reflect some system constrain (throughput, fairness, bottleneck)

        # A poor heuristic fails due to:
        # Ignoring time constraint
        # Assume uniform work across piles (ignoring context of small and large piles)
        # Fails to be guided and modeled by real world issues (congestion, fairness)
    
        # -----------------------------------------------------
        # Solution:

        # total piles
        numPiles = len(piles)

        # ------------
        # Heuristic 1: All Bananas (Throughput Constraint)
        # Spread all bananas evenly over h available hours
        # All bananas / hours -> baseline average k speed

        # Lower Bound: No matter how she distributes her time across piles,
        # if her speed is less than totalBananas/h, 
        # there is not enough total capacity to eat all bananas in h hours
        totalBananas = sum(piles)
        speedCheck1 = math.ceil(totalBananas / h)

        # ------------
        # Heuristic 2: Smallest Bananas (Fair time sharing Constraint)
        # Total hours / num of piles -> = equal time allocated per pile 
        # Find speed k needed to eat smallest pile

        # Lower Bound: min speed required to avoid falling behind schedule 
        # (exceeding per pile time budget) on the easiest pile
        maxEatsForMinElem = int(h/numPiles)
        speedCheck2 = math.ceil(min(piles) / maxEatsForMinElem)

        # ------------
        # Heuristic 3: Largest Bananas (Bottleneck preparing detection Constraint)
        # Allocate Koko 1 hour per pile, excluding the largest one
        # and then spend the remaining time on largest pile.

        # Lower Bound: If her speed is less than this,
        # there is no way to finish the largest pile
        # in the remaining time after handling all other piles
        speedCheck3 = math.ceil(max(piles) / (h - (numPiles - 1)))
        
        # ------------
        # Greedy Starting Speed: Pick the highest lower bound
        speed = max(speedCheck1, speedCheck2, speedCheck3)
        
        # Greedy Search:
        # If totalTime is too large compare to h constraint, double eating k speed
        # If totalTime is close to h constraint, increment speed k by 1
        # search only increases k, never decreases
        while (True):

            # Grab hours needed for current speed
            smallKTotalTime = 0
            for pile in piles:
                smallKTotalTime += math.ceil(pile / speed)

            # Greedy Search: designed to search from lower bound eating speed k
            # Implies: first valid speed we encounter is the smallest one
            if smallKTotalTime <= h:
                return speed

            # if totalTime is too large, double the speed
            elif smallKTotalTime >= 2 * h:
                speed *= 2

            # if close but still too large, we increment the speed by 1
            else:
                speed += 1
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |


## 153. Find Minimum in Rotated Sorted Array ::1:: - Medium

Topics:  Array, Binary Search

### Intro
> Suppose an array of length n sorted in ascending order
> s rotated between 1 and n times. For example, the array nums = [0,1,2,4,5,6,7] might become:
> [4,5,6,7,0,1,2] if it was rotated 4 times.
> [0,1,2,4,5,6,7] if it was rotated 7 times.
> Notice that rotating an array [a[0], a[1], a[2], ..., a[n-1]]
> 1 time results in the array [a[n-1], a[0], a[1], a[2], ..., a[n-2]].
> Given the sorted rotated array nums of unique elements, return the minimum element of this array.
> You must write an algorithm that runs in O(log n) time.

|  Example Input   | Output |  
| ---------------- | ------ | 
| nums = [3,4,5,1,2] | 1 |
| nums = [4,5,6,7,0,1,2] | 0 |  
| nums = [11,13,15,17] | 11 |
 
Constraints:

n == nums.length 

1 &leq; n &leq; 5000

-5000 &leq; nums[i] &leq; 5000

All of the integers of nums are unique 

nums is sorted and rotated between 1 and n times

### Abstraction
Find smallest number in an array that has been rotated some amount of times.

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
|  |  |  |  |  |

| Bug | Error |
| --- | ----- |
|  |  | 

### Brute Force: 
```python
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |


### Find the Bug: 
```python
```

### Solution 1: Find Min by Determining if Smaller Numbers on Left or Right of Middle Binary Search - Binary Search/Condition Adapted Binary Search
```python
    def findMin(self, nums: List[int]) -> int:

        # Note:
        # Modified Binary Search: accounting for rotated property
        
        # Note:
        # Optimization Search: finding the min element
        # We are finding the min element
        # We just need to compare mid against right most element

        # outer elements
        left, right = 0, len(nums) - 1
        
        # Check: If array is not rotated (sorted ascending)
        if nums[left] < nums[right]:
            # min number
            return nums[left]
        
        # binary optimization search with '<' for min value in array
        while left < right:
            mid = (left + right) // 2
            
            # taking advantage property of rotated sorted array:
            # [4, 5, 6, 7, 0, 1, 2]
            # 7 > 2: smaller numbers on right (excluding mid)

            # [0, 1, 2]
            # 1 < 3: smaller numbers on left (including mid)

            # [0, 1]
            # 0 < 1: smaller numbers on left (including mid)

            # [0]
            # return min

            # lower elements on left,
            # implies right half is sorted

            # [10, 1, 2, 3, 6, 7, 8] -> 3 < 8 -> check left
            # if mid elements is less than the rightmost element:
            # higher elements are on the right of mid
            # smaller elements are on the left of mid (including mid)
            # Implies: min is either on mid or to the left
            if nums[mid] < nums[right]:
                right = mid

            # lower elements on right
            # implies left half is sorted

            # [6, 7, 8, 10, 1, 2, 3] -> 10 > 3 -> check right
            # if mid element is greater than the rightmost element then:
            # higher elements are on the left of mid
            # smaller elements are on the right of mid (excluding mid)
            # Implies: min is on the right side
            else:
                left = mid+1
        
        # left == right is the minimum element index
        
        # overall: time complexity O(log n)
        # overall: space complexity O(1)
        return nums[left]
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Binary Search Loop | O(log n) | O(1) | Binary search iteration halves search space due to sorted and rotated property O(log n) | No additional memory allocation O(1) |
| No explicit target | O(1) | O(1) | We are optimizing loop to converge to min O(1) | No additional memory allocation O(1) |
| Overall | O(log n) | O(1) | Binary search over array of n length dominates, leading to O(log n) | No additional memory allocation for binary search |

## 33. Search in Rotated Sorted Array ::1:: - Medium

Topics:  Array, Binary Search

### Intro
> There is an integer array nums sorted in ascending order (with distinct values).
> Prior to being passed to your function, nums is possibly rotated at an unknown pivot index k (1 &leq; k &le; nums.length)
> such that the resulting array is [nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]] (0-indexed).
> For example, [0,1,2,4,5,6,7] might be rotated at pivot index 3 and become [4,5,6,7,0,1,2].
> Notice that rotating an array [a[0], a[1], a[2], ..., a[n-1]]
> Given the array nums after the possible rotation and an integer target, return the index of target if it is in nums, or -1 if it is not in nums.
> You must write an algorithm with O(log n) runtime complexity.

|  Example Input   | Output |  
| ---------------- | ------ | 
| nums = [4,5,6,7,0,1,2], target = 0 | 4 |
| nums = [4,5,6,7,0,1,2], target = 3 | -1 |  
| nums = [1], target = 0 | -1 |
 
Constraints:

1 &leq; nums.length &leq; 5000

-10<sup>4</sup> &leq; nums[i] &leq; 10<sup>4</sup>

All values of nums are unique.

nums is an ascending array that is possibly rotated.

-10<sup>4</sup> &leq; target &leq; 10<sup>4</sup>

### Abstraction
Find target in an array that has been rotated some amount of times.

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
|  |  |  |  |  |

| Bug | Error |
| --- | ----- |
|  |  | 

### Brute Force: 
```python
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |


### Find the Bug: 
```python
```

### Solution 1: Inequality Boundaries Discard Mid Binary Search - Binary Search/Condition Adapted Binary Search
```python
    def search(self, nums: List[int], target: int) -> int:
        
        # Note:
        # Modified Binary Search for rotated property
        # first we check via a middle to right most number number check, 
        # whether the right or left section of mid is sorted

        # with the sorted section, given its boundaries
        # we can check if target lies within sorted range,
        # and by inverse if target lies within the unsorted range

        # outer boundaries
        left, right = 0, len(nums) - 1

        # binary target search with '<='
        while left <= right:

            mid = (left + right) // 2 

            # Check: found target
            if nums[mid] == target:
                return mid

            # guarantees right half is sorted
            if nums[mid] <= nums[right]:
                
                # check if target in right sorted half
                if nums[mid] < target <= nums[right]:
                    left = mid + 1 
                
                # if target does not lie in sorted half,
                # check the non sorted half
                else:
                    # remember, we must discard mid, because we compared to target
                    right = mid - 1      

            # if right half is not sorted,
            # implies that left half is sorted
            else:

                # check if target in left sorted half
                if nums[left] <= target < nums[mid]:
                    right = mid - 1 
                
                # if target does not lie in sorted half,
                # check the non sorted half
                else:
                    # remember, we must discard mid, because we compared to target
                    left = mid + 1

        # no target found

        # overall: time complexity O(log n)
        # overall: space complexity O(1)
        return -1
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Binary search loop | O(log n) | O(1) | Search space halved each iteration O(log n) | No additional memory allocation for iterative binary search O(1) |
| One target comparison | O(1) | O(1) | Mid comparison in constant O(1) | No additional memory allocation for comparison O(1) |
| Overall | O(log n) | O(1) | Binary search over n elements dominates, leading to O(log n) | No additional memory allocation O(1) |

## 981. Time Based Key Value Store ::2:: - Medium

Topics:  Hash Table, String, Binary Search, Design

### Intro
> Design a time based key value data structure that can store multiple values for
> the same key at different time stamps and retrieve the key's value at a certain timestamp.
> Implement the TimeMap class:
> TimeMap(): Initializes the object of the data structure.
> void set(String key, String value, int timestamp): Stores the key key with the value value at the given time timestamp.
> String get(String key, int timestamp): Returns a value such that set 
> was called previously, with timestamp_prev &leq; timestamp. If there are 
> multiple such values, it returns the value associated with the largest 
> timestamp_prev. If there are no values, it returns "".

|  Example Input   | Output |  
| ---------------- | ------ | 
| ["TimeMap", "set", "get", "get", "set", "get", "get"] [[], ["foo", "bar", 1], ["foo", 1], ["foo", 3], ["foo", "bar2", 4], ["foo", 4], ["foo", 5]] | [null, null, "bar", "bar", null, "bar2", "bar2"] |

Constraints:

1 &leq; keys.length, values.length &leq; 100 

key and value consist of lowercase English letters and digits.

1 &leq; timestamp &leq; 10<sup>7</sup>

All the timestamps timestamp of set are strictly increasing.

At most 2 * 10<sup>5</sup> calls will be made to set and get.

### Abstraction
Find target in an array that has been rotated some amount of times.

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
|  |  |  |  |  |

| Bug | Error |
| --- | ----- |
|  |  | 

### Brute Force: 
```python
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |


### Find the Bug: 
```python
```

### Solution 1: Reverse Linear Scan - Binary Search/Condition Adapted Binary Search
```python
    class TimeMap:

        # Note:
        # Stores multiple (value, timestamp) tuples per key in insertion order
        # The 'get' function performs a reverse linear scan to find 
        # the latest time <= the query timestamp.
        # 'get' can be slow if many timestamps per key O(m)

        # space complexity: n is the total set calls across all keys O(n)
        def __init__(self):
            # key -> [(value, timestamp)]
            self.store = {}

        # overall: time complexity O(1) amortized
        def set(self, key: str, value: str, timestamp: int) -> None:
            
            # append to key list:  (value, timestamp)
            if key not in self.store:
                self.store[key] = []
            self.store[key].append((value, timestamp))

        # overall: time complexity where m is number of timestamps for this key O(m)
        def get(self, key: str, timestamp: int) -> str:
            
            # if key list does not exist
            if key not in self.store:
                return ''
            
            # grab key list: [(value, timestamp)]
            values = self.store[key]

            # outer boundaries
            i = len(values) - 1
            
            # Reverse linear scan:
            # grab first valid highest timestamp <= query
            while 0 <= i and values[i][1] > timestamp:
                i -= 1

            # not found case: index -1
            # or
            # timestamp is now <= query
            return values[i][0] if i != -1 else ''

        # overall: time complexity O(m)
        # overall: space complexity O(n)
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| set | O(1) | O(1) | Amortized constant time append O(1) | One tuples stored per call |
| get | O(m) | O(1) | Linear scan backward through at most m timestamps | No additional memory allocation |
| Overall | O(m) | O(n) | get scaling linearly with timestamps count dominates, leading to O(m) | Storage is proportional to total number of sets O(n) |


### Solution 2: Upper Ceiling to Find Highest Timestamp Closest to Query Request - Binary Search/Upper Ceiling or Lower Floor Trick Based on Target Binary Search
```python
    class TimeMap:

        # Note:
        # Upper Ceiling Trick:
        # We cannot directly optimize for 'timestamp <= target' using '<=' via this binary search.
        # Instead, optimize for the condition 'timestamp < target' (strictly greater than).
        # The search finds the index of the first timestamp greater than the target.
        # After, we shift the pointer by one (left - 1) to get the largest timestamp <= target.

        # Note:
        # Stores (value, timestamp) tuples per key in insertion order (sorted by timestamp)
        # 'get' uses binary search to find the largest timestamp <= the query timestamp.
        # 'get' more efficient O(log m)

        # space complexity: n is the total set calls across all keys O(n)
        def __init__(self):
            # key -> [(value, timestamp)]
            self.store = {}

        # overall: time complexity amortized O(1)
        def set(self, key: str, value: str, timestamp: int) -> None:
            
            # append to key list:  (value, timestamp)
            if key not in self.store:
                self.store[key] = []
            self.store[key].append((value, timestamp))

        # overall: time complexity where m is number of timestamps for this key O(log m)
        def get(self, key: str, timestamp: int) -> str:

            # if list does not exist
            if key not in self.store:
                return ''
            
            # grab key list: [(value, timestamp)]
            values = self.store[key]

            # outer boundaries
            left, right = 0, len(values)
            
            # Upper Ceiling Binary Search Shift Trick: 
            # In order to find: highest timestamp <= query
            # First first: query < min timestamp 
            # Then shift index: find highest timestamp <= query
            
            
            # find: query < min timestamp
            # time complexity: binary search over time stamps O(m)
            while left < right:
                
                mid = (left + right) // 2

                # If the timestamp at mid is less than or equal to the query timestamp,
                # then current mid is a valid candidate for '<=',
                # however, we want '<', so we increase mid by 1 
                if values[mid][1] <= timestamp:
                    left = mid + 1
        
                # Todo: ended here
                # Otherwise, the current timestamp is too large,
                else:
                    right = mid

            # shift index: find highest timestamp <= query 
            return values[left - 1][0] if left != 0 else ''      

        # overall: time complexity O(log m)
        # overall: space complexity O(n)
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| set | O(1) | O(1) | Amortized constant time append O(1) | One tuple stored per call O(1) |
| get | O(log m) | Binary search over m timestamps O(log m) | No additional memory allocation for binary search O(1) |  |
| Overall | O(log m) | O(n) | Binary search retrieval dominates, leading to O(log m) | Storage proportional to total number of sets O(n) |

## 4. Median of Two Sorted Arrays ::2:: - Hard

Topics:  Array, Binary Search, Divide and Conquer

### Intro
> Given two sorted arrays nums1 and nums2 of size m and n 
> respectively, return the median of the two sorted arrays.
> The overall run time complexity should be O(log (m+n)).


|  Example Input   | Output |  
| ---------------- | ------ | 
| nums1 = [1,3], nums2 = [2] | 2.00000 |
| nums1 = [1,2], nums2 = [3,4] | 2.50000 |


Constraints:

nums1.length == m 

nums2.length == n 

0 &leq; m &leq; 1000 

0 &leq; n &leq; 1000

1 &leq; m + n &leq; 2000

-10<sup>6</sup> nums1[i], nums2[i] &leq; 10<sup>6</sup>

### Abstraction
Find median between two sorted arrays.

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
|  |  |  |  |  |

| Bug | Error |
| --- | ----- |
|  |  | 

### Brute Force: 
```python
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |


### Find the Bug: 
```python
```

### Solution 1: Two Pointer Merge Until Median - Binary Search/Condition Adapted Binary Search
```python
    def findMedianSortedArrays(self, nums1, nums2):
        
        # Note:
        # 
        
        m, n = len(nums1), len(nums2)
        p1, p2 = 0, 0

        # Helper function to get the smaller of the next available values
        def get_min():
            nonlocal p1, p2
            if p1 < m and p2 < n:
                if nums1[p1] < nums2[p2]:
                    ans = nums1[p1]
                    p1 += 1
                else:
                    ans = nums2[p2]
                    p2 += 1
            elif p2 == n:
                ans = nums1[p1]
                p1 += 1
            else:
                ans = nums2[p2]
                p2 += 1
            return ans

        # Calculate median depending on total length parity
        if (m + n) % 2 == 0:
            for _ in range((m + n) // 2 - 1):
                _ = get_min()
            return (get_min() + get_min()) / 2
        else:
            for _ in range((m + n) // 2):
                _ = get_min()
            return get_min()
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |


### Solution 2: Binary Search Partition - Binary Search/Condition Adapted Binary Search
```python
   def findMedianSortedArrays(self, nums1, nums2):

        # Note:
        # 

        # Ensure nums1 is the smaller array
        if len(nums1) > len(nums2):
            nums1, nums2 = nums2, nums1

        m, n = len(nums1), len(nums2)
        low, high = 0, m

        while low <= high:
            partitionX = (low + high) // 2
            partitionY = (m + n + 1) // 2 - partitionX

            # Edge cases for partitions
            maxLeftX = float('-inf') if partitionX == 0 else nums1[partitionX - 1]
            minRightX = float('inf') if partitionX == m else nums1[partitionX]

            maxLeftY = float('-inf') if partitionY == 0 else nums2[partitionY - 1]
            minRightY = float('inf') if partitionY == n else nums2[partitionY]

            # Check for correct partition
            if maxLeftX <= minRightY and maxLeftY <= minRightX:
                if (m + n) % 2 == 0:
                    return (max(maxLeftX, maxLeftY) + min(minRightX, minRightY)) / 2
                else:
                    return max(maxLeftX, maxLeftY)
            elif maxLeftX > minRightY:
                high = partitionX - 1
            else:
                low = partitionX + 1 
```
|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |