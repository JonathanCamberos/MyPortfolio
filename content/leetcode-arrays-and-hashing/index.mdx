---
title: "LeetCode: Arrays & Hashing"
description: "arrays & hashing"
image: "../../public/blogs/hashmap-8.png"
publishedAt: "2025-05-13"
updatedAt: "2025-05-26"
author: "jonathancamberos"
isPublished: true
tags:
- data structures & algorithms
---

## Arrays & Hashing Intro:

Leetcode problems with elegant solutions using hashing. 

### What is a Hashmap
A dictionary is just a direct mapping of keys->values:

Dictionary: ['a': 2, 'b': 2, 'c' : 3, ...] 

A Hashmap is just a dictionary that maps keys->values using a hash function.
Hashmaps are a common use case for hashing.
We choose hashing to maximize randomness and minimize collisions between elements to keys.

### Hashing Benefits
Hashing is simply a function. It takes in an input, and spits out an output.
As an example, here is the function mod, which takes in an integer and spits out an integer:

1 mod (3) = 1

2 mod (3) = 2

3 mod (3) = 0

4 mod (3) = 1

Now this is could be our function for our hashmap, but it would lead to high collisions and low randomness
as there are only 3 possible key results: 0, 1, and 2.
So hashmaps are only efficient as the chosen function.

With a good Hash function:

Insert, Lookup, and Delete take O(1).
In this case, every element gets its own unique key and so
a lookup using this function would be constant O(1).

With a bad Hash function:

Insert, Lookup, and Delete take O(n). 
Lets say our function is hash():

```
    hash()  ->  [key mod (5)]
    hash(10) = 10 % 5 = 0
    hash(22) = 22 % 5 = 2
    hash(31) = 31 % 5 = 1
    hash(14) = 14 % 5 = 4
    hash(17) = 17 % 5 = 2 (collision!)

    Handle collision using chaining with a linked list of elements.

    Index 0  |  Index 1  |  Index 2         |  Index 3  |  Index 4
    -------- | --------- | ---------------- | --------- | ---------
    [10]     |  [31]     |  [22 -> 17]      |  [  ]     |  [14]
```

In this case there are only 5 keys or buckets would be hashed to.
After inserting n elements into one key or bucket, performing a lookup would for some element k 
would result in traversing a list of size n in the worst case leading to O(n).

This would degrade insert, lookup, and delete from the original O(1) to O(n).

### Balancing
Balancing occurs when a hash table has passed its set load factor.

Load Factor = n/m
Where n = num of elements, m = num of keys

Thus, when certain fraction of the table size, say 75% full with 3 elements and 4 potential keys. 
The table must increase in size and rehash/reinsert every element. 

The efficiency of a hash table decreases significantly without balancing, as this leads to increased collisions as the table fills up,
which leads to time needed to resolve collisions, as we traverse through list to find the element in linear time O(n).
Operations like search, insert, and delete, degrade from O(1) on average to O(n) in the worst case.

Usually, when the load factor is reached, the table size doubles to 2n.
And usually, a common load factor is 0.75 or 75% full.
Finally, we must rehash every element leading to:
[(double table size * load factor) - current n elements] = 

(2n * 0.75) - n  =

1.5n - n =

0.5n =

n/2 = additional space after rebalancing

Rehashing is notably expensive as we must rehash every element with the new hash function, 
leading to O(n) for resizing and reinserting n elements.


### Application
Hashmaps having quick O(1) average time for insert(), lookup(), and delete(), 
are great for storing key pairs of lists of elements to perform more complex tasks 
where performance in time and space complexity are important.


## 217. Contains Duplicate - Easy

### Intro
> Given an integer array nums, return true if any value appears at least twice in the array, 
> return false if every element is distinct.

|  Example Input           | Output |  
| ---------------- | ------ | 
| nums = [1,2,3,1] | true   |
| nums = [1,2,3,4] | false  |  
| nums = [1,1,1,3,3,4,3,2,4,2] | true |
 
Constraints:

Array Length: 1 &le; nums.length &le; 10<sup>5</sup>

Integer Size: -10<sup>9</sup>  &le; nums[i] &le; 10<sup>9</sup> 


### Abstraction
Given a list of elements, we need to check if any of those elements are duplicated.

Time Lower Bound: 
We are required to traverse the list to peak at every element at least once, best possible time complexity is O(n).

Space Upper Bound: 
If we want to track every element, best space complexity is O(n)

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
| Brute Force (all pairs comparison) | O(n<sup>2</sup>) | O(1) | For each pair of elements, we compare them, leading to quadratic number of comparison O(n<sup>2</sup>)  | No additional memory is allocated O(1) |
| Hashmap | O(n) | O(n) | Iterate over every element O(n), with O(1) lookup and insertion into the map, leading to linear time O(n) | We store each each element in a hashmap, which requires additional memory proportional to the number of elements O(n) |
| Hashset | O(n) | O(n) | Same logic as Hashmap | Same logic as Hashmap |


### Brute Force (all pairs comparison)
```python
    def containsDuplicate(self, nums: List[int]) -> bool:

        # time complexity: iteration of O(n)
        for i in range(len(nums)):

            # time complexity: iteration of O(n^2)
            # 1 + 2 + 3 ... (n - 3) (n - 2) (n - 1) -> 
            # sandwich with reverse sum and cross out like terms -> n(n-1)/2 = O(n^2)
            for j in range(i + 1, len(nums)):

                # time complexity: comparison O(1)
                if nums[i] == nums[j]:
                    return True
        
        # overall: time complexity O(n^2) 
        # overall: space complexity O(1)
        return False
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Outer Loop | O(n) | O(1) | Iteration over the list takes linear time O(n) | No additional memory is allocated O(1) |
| Inner Loop | O(n<sup>2</sup>) | O(1) | For each element in the outer loop, the inner loop iterates through all subsequent elements with Big(O) is O(n<sup>2</sup>). Derivation [here](/blogs/common-formulas#brute-case-double-for-loop) | No additional memory is allocated O(1) |
| Comparison | O(1) | O(1) | Each pair of elements is compared in constant time O(1) | No additional memory is needed for comparisons O(1) |
| Overall | O(n<sup>2</sup>) | O(1) | The inner loop dominates leading to O(n<sup>2</sup>) time complexity.| No additional memory was allocated leading to constant O(1) space complexity. | 


### Solution 1: Hashmap
```python
    def containsDuplicate(self, nums: List[int]) -> bool:

        # space complexity: hashmap of O(n)
        seen = {}

        # time complexity: iteration of O(n)
        for num in nums:

            # time complexity: lookup operation of O(1)
            if num in seen:
                return True
            seen[num] = 1

        # overall: time complexity  O(n)
        # overall: space complexity O(n)
        return False
```
```python
    def containsDuplicate(sef, nums: List[int]) -> bool:

        # space complexity: dictionary of O(n)
        # dictionary auto initializes missing key's values to 0
        seen = defaultdict(int)

        # time complexity: iteration of O(n)
        for num in nums:

            # time complexity: indexing of O(1)
            if seen[num] >= 1:
                return True
            seen[num] += 1

        # overall: time complexity  O(n) 
        # overall: space complexity O(n)
        return False
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iteration + Insertion | O(n) | O(n) | Iteration over the list takes linear time O(n) with insertion into Hashmap in O(1) time. Iteration dominates O(n). | Hashmap grows proportional to the number of unique elements. Worst case O(n) |
| Lookup | O(1) | O(1) | Each lookup is O(1), performed once per element | Lookup operations do not require additional memory allocation. |
| Overall | O(n) | O(n) | Iteration dominates over insertion for time complexity linearly for O(n) | Memory allocation for Hashmap dominates leading to O(n) space complexity.  | 


### Solution 2: Hashset

```python
    def containsDuplicate(self, nums: List[int]) -> bool:
        
        # space complexity: hashset of O(n)
        seen = set()

        # time complexity: iteration of O(n)
        for n in nums:

            # time complexity: lookup operation of O(1)
            if n in seen:
                return True
            seen.add(n)
            
        # overall: time complexity  O(n)
        # overall: space complexity O(n)
        return False
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iteration + Insertion | O(n) | O(n) | Iteration over the list takes linear time O(n) with insertion into Hashset in O(1) time. Iteration dominates O(n). | Hashset grows proportional to the number of unique elements. Worst case O(n) |
| Lookup | O(1) | O(1) | Lookup operation O(1), performed once per element, is still O(1) | Lookup operations do not require additional memory allocation. O(1) |
| Overall | O(n) | O(n) | Iteration dominates over insertion for time complexity linearly for O(n) | Memory allocation for Hashset dominates leading to O(n) space complexity.  | 


## 242. Valid Anagram - Easy

### Intro

> Given two strings s and t, return true if t is an anagram of s, and false otherwise.

An Anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once.


|  Example Input 'S'  | Example Input 'T' | Output |  
| ------------------- | ----------------- | ------ | 
| "anagram"           | "nagaram"         | true   |
| "rat"               | "car"             | false  |  


Constraints:

String Length: 1 &le; s.length, t.length &le; 5 * 104

Characters: s and t consist of lowercase English letters

### Abstraction

Given a string, we represent its character count as a Hashmap.
We then validate it to the second string character count.

Time Lower Bound: We are required to traverse both strings to peak at every element at least once, best possible time complexity is O(n).

Space Upper Bound: If we want to track every element, best space complexity is O(n)

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
| Brute Force (Merge sort on strings) | O(n log n) | O(n) | Sorting an individual string O(n log n) dominates as comparing strings by character sequentially is linear O(n) | No additional memory is allocated O(1) |
| Hashmap | O(n) | O(n) | Iteration over the list takes linear time O(n), with O(1) lookup and insertion into the map, leading to linear time O(n) | We store each each element in a hashmap, which requires memory proportional to the number of elements O(n) |
| Hashmap (array of 26) | O(n) | O(n) | Same as logic as Hashmap | Same as logic as Hashmap |

### Brute Force (Merge sort on strings)
```python
    def isAnagram(self, s: str, t: str) -> bool:
        
        # time complexity: comparison of O(1)
        if len(s) != len(t):
            return False
        
        # time complexity: sorting of O(n log n) for sorting each string
        # space complexity: overall of O(n) = temporary arrays O(n) + recursion stack of O(log n)
        def mergeSort(string):
            
            # base case of list with single element
            # time complexity: O(1)
            # space complexity: O(1)
            if len(string) <= 1:
                return string
            
            # time complexity: dividing operation O(1)
            mid = len(string) // 2

            # mergeSort both subarrays -> mergeSort time/space complexity * 2
            left = mergeSort(string[:mid])
            right = mergeSort(string[mid:])
            
            return merge(left, right)
        
        # Time Complexity: O(n) per merge
        # Space Complexity: O(n) for temporary storage of the merged array
        def merge(left, right):
        
            sorted = []
            i = j = 0

            while i < len(left) and j < len(right):
                if left[i] <= right[j]:
                    sorted.append(left[i])
                    i += 1
                else:
                    sorted.append(right[j])
                    j += 1
            

            # time complexity: O(n) in worst case if 1 list is empty
            sorted.extend(left[i:]) # If elements remain in `left`
            sorted.extend(right[j:]) # If elements remain in `right`

            return sorted

        # Time Complexity: O(n log n) for sorting each string
        # Space Complexity: O(n) for temporary arrays and recursion stack
        sorted_s = mergeSort(list(s))
        sorted_t = mergeSort(list(t))


        # overall: time complexity: O(n log n)
        # overall: space complexity: O(n)
        return sorted_s == sorted_t
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Sorting | O(n log n) | O(n) | Sorting the strings involves recursively dividing the input and merging them back leading to O(n log n) time complexity. Merge sort derivation [here](/blogs/common-formulas#merge-sort). | Temporary arrays are used during merging, leading to O(n) space |
| Comparison | O(n) | O(1) | Comparing the sorted strings character by-element takes linear time | No additional memory is allocated O(1) |
| Overall | O(n log n) | O(n) | Sorting dominates the time complexity as comparison adds negligible overhead leading to O(n log n) time complexity. | Temporary arrays required for merge sort is proportional to input size leading to O(n) space complexity. |


### Solution 1: Hashmap

```python
    def isAnagram(self, s: str, t: str) -> bool:
        
        # space complexity: hashmap of O(n) 
        count = defaultdict(int)

        # time complexity: iteration of O(n)
        for x in s:
           count[x] += 1

        # time complexity: iteration of O(n)
        for x in t:
           count[x] -= 1

        # time complexity: iteration of O(n)
        for value in count.values():

            # time complexity: comparison of O(1)
            if value != 0:
                return False

        # overall: time complexity  O(n)
        # overall: space complexity O(n)
        return True
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iteration + Insertion | O(n) | O(n) | Iterating over the first string takes linear time O(n) with O(1) insertion. | Hashmap size depends on the number of unique characters in the input. Worst case O(n) |
| Editing Map | O(n) | O(1) | Iterating over the second string to edit the Hashset takes linear time O(n) | No additional memory is allocated O(1) |
| Verification | O(n) | O(1) | Iterating over the Hashmap takes linear time O(n) | No additional memory is allocated O(1) |
| Overall | O(n) | O(n) | Character counting and verification result in O(3n) which Big(O) abstracts to O(n). | Memory allocation for Hashmap dominates leading to O(n) space complexity |

### Solution 2: Hashmap (array of 26)
```python
    def isAnagram(self, s: str, t: str) -> bool:

        # space complexity: fixed size constant 26 element array O(1)
        count = [0] * 26

        # time complexity: iteration of O(n)
        for x in s:
           count[ord(x) - ord('a')] += 1

        # time complexity: iteration of O(n)
        for x in t:
           count[ord(x) - ord('a')] -= 1

        # time complexity: iteration of O(n)
        for value in count:

            # time complexity: comparison of O(1)
            if value != 0:
                return False

        # overall: time complexity: O(n)
        # overall: space complexity O(1)
        return True
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iteration + Insertion | O(n) | O(1) | Iterating over the first string to populate the Array takes linear time O(n) | Fixed-sized array of 26 elements is used O(1) |
| Editing Array | O(n) | O(1) | Iterating over the second string to edit the Array takes linear time O(n) | No additional memory is allocated O(1) |
| Verification | O(n) | O(1) | Iterating over the Array takes linear time O(n) | No additional memory is allocated O(1) |
| Overall | O(n) | O(1) |  counting and verification result in O(3n) which Big(O) abstracts to O(n) | Space usage optimal due to a constant size array O(1) |


## 1. Two Sum - Easy

### Intro
> Given an array of integers nums and an integer target, return indices of the two numbers
> such that they add up to target. You may assume that each input would have exactly one solution, 
> and you may not use the same element twice. You can return the answer in any order.

|  nums[]         | Target    | Output |  
| --------------- | ----------| ------ | 
| [2,7,11,15]     | 9         | [0,1]  |
| [3,2,4]         | 6         | [1,2]  |  
| [3,3]           | 6         | [0,1]  |

Constraints:

Only one valid answer exists

Target = n + m, n/m value: 2 &le; nums.length &le; 10^4

Target value: -10^9 &le; target &le; 10^9

### Abstraction
We must find a combination of two elements in the array that add up to the target. 

Lets say we were to iterate over the array linearly in O(n). 
At any given moment, if we are pointing to some index n, 
we would only have half of a potential solution. We would still need to confirm that a second element adds up to target. 

Note that during this linear iteration, we would still have access to the target.

Since we are finding (target = currNum + complement) we can do (target - currNum = complement) 
and get the second half of the solution.
If this complement is present in the Array, then that is our final solution. 
Our next step is finding that complement.

Since we are traversing the array, we can build up a hashset of elements we have seen, and use these as a 
complement -> key -> index mapper for future elmements.

The pattern to find the pair is is to iterate, grab element in array, caluclate the complement, 
and check if complement is inside hashset.

Finally, since the question asks us to return the index of the pair, we must use a Hashmap with
(element, index) where element is the complement that maps to the it's index in the Array.

Time Lower Bound: We are required to traverse the list to peak at every element at least once, best possible time complexity is O(n).

Space Upper Bound: If we want to track every element/complement, best space complexity is O(n)

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
| Brute Force (Comparing all pairs) |  |  |  | |
| Hashmap 1-pass |  |  |  |  |


### Brute Force (Comparing all pairs)
```python
    def twoSum(self, nums: List[int], target: int) -> List[int]:
        
        # time complexity: iteration of O(n)
        for i in range(len(nums)):

            # time complexity: iteration of O(n^2) 
            # 1 + 2 + 3 ... (n - 3) (n - 2) (n - 1) -> 
            # sandwich with reverse sum and cross out like terms -> n(n-1)/2 = O(n^2)
            for j in range(i + 1, len(nums)):

                # time complexity: summation + comparison of O(1)
                if nums[i] + nums[j] == target:
                    return [i, j]

        # overall: time complexity  O(n^2) 
        # overall: space complexity O(1)
        return []
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Outer Loop | O(n) | O(1) | Iterates over the array once for each element O(n) | No additional memory is allocated O(1) |
| Inner Loop | O(n<sup>2</sup>) | O(1) | For each element in the outer loop, iterates through all remaining elements O(n<sup>2</sup>)  | No additional memory is allocated O(1) |
| Summation + Comparison | O(1) | O(1) | Summing two numbers takes constant time O(1) and comparison to target takes constant time O(1) | No additional space is needed for summation O(1), no additional space is needed for comparison O(1)  |
| Overall | O(n<sup>2</sup>) | O(1) | The nested loops result in O(n<sup>2</sup>) time complexity. Derivation of average case is found O(n<sup>2</sup>) is found [here](/blogs/common-formulas#brute-case-double-for-loop). | No additional space was allocated, so it is independent of input size O(1) | 


### Solution 1: Hashmap 1-pass
```python
    def twoSum(self, nums: List[int], target: int) -> List[int]:
        
        # map of {complement: index, complement: index...}
        # space complexity: hashmap of O(n)
        tracking = {}
 
        # time complexity: iterating over list of size n O(n)
        for i in range (len(nums)):

            # grab curr complement -> (target = nums[i] + complement) 
            # time complexity: subtraction O(1) 
            complement = target - nums[i]

            # time complexity: lookup operation O(1)
            if complement in tracking:
                
                # [curr_index, complement_index]
                return [i, tracking[complement]]
    
            # if miss, track currElement as potential complement
            # time complexity: insert operation O(1)
            tracking[nums[i]] = i

        # overall: time complexity  O(n) 
        # overall: space complexity O(n)
        return []
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iteration + Insertion | O(n) | O(n) | Iterating over the first string to populate a Hashmap takes linear time O(n) | Hashmap size is proportional to the number of unique integers. Worst case O(n). |
| Lookup | O(1) | O(1) | Each lookup operation takes constant O(1) time. | Lookups do not require additional memory. |
| Insertion | O(1) | O(n) |Each insertion operation takes constant O(1) time. | Hashmap size is proportional to the number of unique integers. Worst case O(n). |
| Overall | O(n) | O(n) | Iterating dominates time complexity leading to linear O(n) time complexity. | Memory allocation for Hashmap dominates leading to O(n) space complexity. |


## 49. Group Anagrams - Medium

### Intro
> Given an array of strings strs, group the anagrams together. You can return the answer in any order.
> An Anagram is a word or phrase formed by rearranging the letters of a different word or phrase, 
> typically using all the original letters exactly once.

|  Input                                   | Output                                      |  
| ---------------------------------------- | ------------------------------------------- | 
| ["eat","tea","tan","ate","nat","bat"]    | [["bat"],["nat","tan"],["ate","eat","tea"]] |
| [""]                                     | [[""]]
| ["a"]                                    | [["a"]]           


Constraints:

strs[i] consists of lowercase English letters


### Abstraction
There are different ways to solve this problem. 

One premise is that a string can be represented as a Hashmap of character counts.
We could then use the Hashmaps as keys which would group anagrams in a list of strings:
Hashmap(Hashmap(char_count) -> [anagram list string]) 

Another premise is we could sort the string and use that as the key: 
Hashmap ( sorted_string -> [[unsorted anagram string group]])

Time Lower Bound: We are required to traverse the list to peak at every string at least once O(n). We also need to calculate character frequencies to determine anagrams O(k). Best possible time complexity is O(n * k).

Space Upper Bound: If we want to track every character count Hashmap per every string, best space complexity is O(n * k)

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
| Brute Force (Merge sort to group hashmap values by sorted key) | O(n<sup>2</sup> * k) | O(1) | For each pair of strings, we compare them leading to O(n<sup>2</sup>). Using a Hashmap to check if they are anagrams takes O(k). Leading to O(n<sup>2</sup> * k)  | Stores temporary intermediate groups in a list |
| Merge sort | O(n * k log k) | O(n * k) | Iterating over the Array takes O(n). Sorting each string with merge sort takes O(k log k). Leading to O(n * k log k) | Requires storage for sorted strings O(k) for O(n) strings, groups are stored in memory |
| Hashmap | O(n * k) | O(n * k) | Iterating over the Array takes O(n). Computing character count per string takes O(k). Leading to O(n * k) | Creates a Hashmap per string O(n) for k character key map per string O(k). Leading to O(n * k)|

### Brute Force (Merge sort to group hashmap values by sorted key)
Not shown in code as is inefficient with O(n<sup>2</sup> k). It checks each string against every other
for inequality.

### Solution 1: Sort Grouping - Merge sort
```python 
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:
        
        # time complexity: O(k log k) = merge two halves O(k) * num of levels of recursion O(log k) 
        # space complexity: O(k) = temporary array during merging O(k) + recursion stack memory O(log k)
        def mergeSort(word):
        
            # base case: list with 1 element
            # time complexity: O(1)
            # space complexity: O(1)
            if len(word) <= 1:
                return word
            
            mid = len(word) // 2
            

            # space complexity: temporary array O(k) + recursion stack memory O(log k)
            left = mergeSort(word[:mid])
            right = mergeSort(word[mid:])
            
            # space complexity: temporary array O(k)
            sorted = []
            i = j = 0
            
            # time complexity: iteration of both subarrays O(n)
            # space complexity: temporary arrays of O(n)
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    sorted.append(left[i])
                    i += 1
                else:
                    sorted.append(right[j])
                    j += 1
            
            # Adding remaining elements from either half
            sorted.extend(left[i:])  # time complexity: O(n)
            sorted.extend(right[j:]) # time complexity: O(n)

            return ''.join(sorted_word)
    
        # space complexity: O(n * k) = for n sorted string key O(n) and original string value of length k O(k)
        anaGroup = {}
        
        # time complexity: O(n * k log k), where n is number of strings and k is maximum length
        for word in strs:
            
            # time complexity: merge sort O(k log k)
            sorted = mergeSort(word)

            # time complexity: lookup + insertion O(1)
            if sorted in hashmap:
                hashmap[sorted].append(word)
            else:
                hashmap[sorted] = [word]
        

        # overall: time complexity 
        # overall: space complexity
        return list(anaGroup.values())
``` 

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Merge Sort per string | O(k log k) | O(k) | Sorting a single string of length k.  | Temporary arrays O(k) and recursion stack O(log k) |
| Sorting all strings | O(n * k log k) | O(k) (temporary per string sequentially)  | Sorting n strings, each of length k | O(k) per string dominates recursion stack O(log k)  |
| Hashmap insertion | O(1) | O(n * k) | Lookup and insertion are O(1)  | Memory allocation for sorted n string keys O(n) * original string values O(k) |
| Overall | O(n * k log k) | O(n * k) |  Merge sort O(k log k) for all strings O(n) dominates. Leading to O(n * k log k) |  Storing sorted string keys O(n) with original string value O(k) dominates. Leading to O(n * k) |


### Solution 2: Hashmap -> Tuple Key Grouping
```python
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:
        
        # Note: Tuples in python are immutable which makes them suitable as 
        # keys for a hashmaps, as you canâ€™t do that with a list. 
        # You should use tuples where the position carries symantec meaning. 

        # [26 char count tuple key -> [anagram group list], ...]
        # space complexity: O(n * k) = hashmap stores n tuple keys and lists of original strings with length k
        anaGroup = {}

        # time complexity: iterating over all strings O(n) 
        for word in strs:
            
            # space complexity: fixed-sized array for 26 lowercase letters O(1)
            char_count = [0] * 26  
            
            # time complexity: counting chars in string of k length O(k)
            for char in word:
                char_count[ord(char) - ord('a')] += 1
            
            # space complexity: fixed-size tuple of length 26 O(1)
            key = tuple(char_count)  
            
            # time complexity: lookup operation of O(1) 
            if key not in anaGroup:
                anaGroup[key] = []  

            # time complexity: append operation to list O(1)
            anaGroup[key].append(word)  


        # overall: time complexity  O(n * k)  
        # overall: space complexity O(n * k)
        return list(anaGroup.values())
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iterating over strings  | O(n) | O(1) | Loop over n strings O(n) | No additional memory per iteration O(1) |
| Counting Characters | O(k) per string | O(1) | counting characters for string k length O(k) | fixed-sized array for 26 chars O(1) |
| Tuple | O(1) | O(1) | Converting fixed-size array to tuple in constant O(1) | fixed-size tuple of 26 elements O(1) |
| Lookup in hashmap | O(1) | O(n * k) | Lookup operation takes constant O(1) | For n string keys of length k O(n * k)  |
| Appending to list | O(1) | O(n * k) | Appending operation takes constant O(1) | Hashmap of n keys to list of strings k length O(n * k) |
| Overall | O(n * k) | O(n * k) | Iteration and character counting dominates with O(n * k) | Memory allocation for n string keys with for list of strings k length dominates with O(n * k) |


### Solution 3: Hashmap -> Manual Key Grouping

```python
    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:

        # space complexity: hashmap of n string keys to list of strings k length O(n * k)
        anaGroup = {}

        # time complexity: iterating over n strings O(n)
        for word in strs:

            # space complexity: fixed-sized array of 26 lowercase characters O(1)
            char_count = [0] * 26
            
            # time complexity: counting characters for string k length O(k)
            for char in word:
                char_count[ord(char) - ord('a')] += 1
            
            # time complexity: creating unique char count key from fixed-sized array of 26 O(1)
            key = ""
            for count in char_count:
                key += str(count) + "#"  # Separator between counts

            # time complexity: lookup operation for key O(1)
            if key not in anaGroup:
                anaGroup[key] = []  # Initialize list for key if doesn't exist
            anaGroup[key].append(word)  # Add word to corresponding key group

        # overall: time complexity
        # overall: space complexity 
        return list(anaGroup.values())
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iterating over strings | O(n) | O(1) | Iterating over n strings O(n) | No additional memory per iteration O(1)  |
| Counting Characters | O(k) per string | O(1) | Counting characters for string k length | Fixed-sized character count array of 26 lowercase letters O(1) |
| Key Generator | O(1) | O(1) | Iterating over fixed-sized 26 character array to generate key O(1) | Unique string key generated O(1) |
| Lookup in hashmap | O(1) | O(n * k) | Lookup operation in hashmaps takes constant O(1) | Hashmap of n string keys to list of strings k length O(n * k)   |
| Appending to list | O(1) | O(1) | Appending operation to list takes constant O(1) | No additional memory required for append O(1) | 
| Overall | O(n * k) | O(n * k) | Iterating over n strings and counting characters for strings k length dominates O(n * k) | Hashmap of n string keys with lists of strings k length dominates O(n * k) |


## 347. Top K Elements in List - Medium

### Intro
> Given an integer array nums and an integer k, return the k most frequent element within the array. 
> Test cases are generated such that the answer is always unique. You may return the output in any order

|  Input             | k     | Output    |  
| -------------------| ----- | --------- | 
| [1,2,2,3,3,3,3]    | 2     | [2,3]     |
| [7,7]              | 1     | [7]       |

Constraints:

Most Occurrences: 1 &le; k &le; number of distinct elements in nums
Integer value: -1000 &le; nums[i] &le; 1000

### Abstraction
To find the k most frequent elements, we must first create an occurrence counter for each element in the list.
Now that we have the count, we just grab the top k highest occurring elements. 

Here the are a few ways to implement that.

Time Lower Bound: 

Space Upper Bound: 


### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
| Brute Force (Insertion sort frequencies) | O(m<sup>2</sup>) | O(n + k) | Insertion sort on m unique elements dominates leadin | |
| Frequency Buckets | O(n) | O(n) | | |

### Brute Force (Insertion Sort on frequency tuples descending)

```python
    def topKFrequent(self, nums: List[int], k: int) -> List[int]:
        
        # space complexity: frequency count for all unique integers O(m)
        count = defaultdict(int)

        # time complexity: iterate over list of n integers O(n)
        for num in nums: 

            # time complexity: insertion operation takes constant O(1)
            count[num] += 1


        # time complexity: iteration for conversion to list takes O(m)
        # space complexity: list size is equal to number of unique integers O(m)
        countTuple = list(count.items()) # [(num, freq), ...]

        # time complexity: Insertion sort 
        # Best case O(m), Average O(m) = O(m^2/2), Worst O(m^2)
        for i in range(1, len(countTuple)):
            key = countTup[i]
            j = i - 1

            # while left element is greater than key
            while j >= 0 and countTuple[j][1] < key[1]:
                countTuple[j + 1] = countTuple[j]
                j -= 1
            
            countTuple[j + 1] = key # place key

        # time complexity: grab k top occurring ints from frequency list O(k)        
        result = []
        for i in range(k):
            
            # grabbing int key from tuple [(int, count), ...]
            result.append(countTuple[i][0]) 

        # overall: time complexity  O(m^2) = O(n + m^2 + k)
        # overall: space complexity O(m)
        return result
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iteration + Insertion | O(n) | O(m) | Iterating over array of n integers O(n) | Hashmap with m unique elements results in O(m) memory allocation with O(n) in worst case |
| Conversion to list | O(m) | O(m) | Iterating over hashmap to create list takes O(m) | List of tuples stores m (int, count) pairs O(m) |
| Insertion sort | Best O(m), O(m<sup>2</sup>) average, O(m<sup>2</sup>) worst | Insertion sort on tuples of (int, count) sorting by count results in usual time complexity of insertion sort | No additional memory allocation required for in-place insertion sort O(1) |  |
| Grabbing top-k elements | O(k) | O(k) | Iterating over sorted list for k elements O(k) | Storing top k elements into result array O(k) | 
| Overall | O(m<sup>2</sup>) | O(m) | Insertion sort dominates leading to O(m<sup>2</sup>) | Hashmap and list for m unique elements dominates leading to O(m) |


### Solution 1: Bucket Sort

```python
    def topKFrequent(self, nums: List[int], k:int) -> List[int]:
            
        # space complexity: frequency count for unique integers O(m) 
        count = defaultdict(int)

        # time complexity: iterate over list of n integers O(n)
        for key in nums:

            # time complexity: insertion operation takes constant O(1)
            count[key] += 1

        # numBuckets equal to length to account for max possible frequency count
        # the case where list is full of only 1 element O(n)
        # + 1 for case of element with 1 list, need bucket of frequency 0 and bucket of frequency 1
        numBuckets = len(nums) + 1

        # time complexity: iterating to set empty list for each bucket
        # space complexity: creating O(n) bucket lists
        freqBuckets = [[] for i in range(numBuckets)]

        # time complexity: iterate over frequency list for m unique integer tuples (int, occurrences) O(m) 
        for int, occurrences in count.items():

            # time complexity: insert operation takes constant O(1)
            freqBuckets[occurrences].append(int)

        # space complexity: grabbing top k integers O(k)
        res = []

        # time complexity: iterate over n buckets O(n)
        for i in range(len(freqBuckets) - 1, 0, -1):
            
            # time complexity: iterate over all entries in current bucket O(n)
            for num in freqBuckets[i]:
                
                # time complexity: insert operation takes constant O(1)
                res.append(num)
                
                # time complexity: continue while less than k integers have been grabbed O(k)
                if len(res) == k:
                    return res

        # overall: time complexity O(n)
        # overall: space complexity O(n)
        return []
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Iteration + Insertion | O(n) | O(m) | Iteration over array of n integers O(n) | Hashmap for m unique integers O(m) |
| Bucket Initialization | O(n) | O(n) | Iterating over list length to create n empty buckets O(n) | At least n buckets needed for worst case scenario of list filled with only 1 integer O(n) |
| Bucket Population | O(m) | O(m) | Inserting m unique integers into their respective buckets |  Buckets will store m unique integers in their respective buckets O(m) |
| Result Extraction | O(n) | O(k) | Iterating over n buckets to collect k integers, worst case all buckets must be traverse O(n) | Top k integers must be stored in result list O(k) | 
| Overall | O(n) | O(n) | Iterating over n buckets dominates leading to O(n) | Initializing n buckets dominates leading to O(n) |


## 238. Product of Array Except Self - Medium

### Intro
>Given an integer array nums, return an array answer such that answer[i] is 
>equal to the product of all the elements of nums except nums[i].
>The product of any prefix or suffix of nums is guaranteed to fit in a 32-bit integer.
>You must write an algorithm that runs in O(n) time and without using the division 
>operation.

|  Input         | Output          |  
| -------------- | --------------- | 
| [1,2,3,4]      | [24,12,8,6]     |
| [-1,1,0,-3,3]  | [0,0,9,0,0]     |

Constraints:

The product of any prefix or suffix of nums is guaranteed to fit in a 32-bit integer

### Abstraction
Given a list of nums, return a list of nums that is the product of the array except itself.

So, for some num n, the result should be the product of all the numbers to the left of it,
times the product of all the numbers to the right of it:

```
Array:           [   2,    3,    4,    5,    6  ]

Prefix:          [   1,    2,    6,   24,  120  ]
x
Postfix:         [ 360,  120,   30,    6,    1  ]
=
Result:          [ 360,  240,  180,  120,  120  ]
```

To calculate the prefix, we can just iterate over the array multiplying each integer.
To calculate the postfix, we can just iterate over the array backwards multiplying each integer. 
And to calculate the result array, we can just iterate over both arrays and multiple corresponding index values.

This would lead to O(n) for time and space. 
Lets see how we can do it in O(1) for space.

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
| Brute Force (all pairs comparison) | O(n<sup>2</sup>) | O(n) | For each pair of elements, we compare them, leading to quadratic number of comparison O(n<sup>2</sup>) | Memory allocation for result array O(n) |
| Prefix & Postfix | O(n) | O(n) | Three iterations over the array for prefix, postfix, and result calculation O(n) = O(3n)  | Memory allocation for prefix, postfix, and result arrays O(n) = O(3n) |
| Prefix & Postfix | O(n) | O(1) | Two iterations over the array for prefix and postfix calculations O(n) |  |

### Brute Force (all pairs comparison)
```python
    def productExceptSelf(self, nums: List[int]) -> List[int]:

        # space complexity: result array of length n O(n)
        res = [0] * len(nums)

        # time complexity: iterate over list of n integers O(n) 
        for i in range(len(nums)):

            # starting value
            product = 1

            # time complexity: iterate over list of n integers O(n)
            for j in range(n):

                # skip current index i while multiplying
                if i != j:

                    # time complexity: multiplication operation takes constant O(1)
                    product *= nums[j]
                
            # time complexity: insert operation takes constant O(1)
            res[i] = product
        
        # overall: time complexity  O(n^2)
        # overall: space complexity O(n)
        return res
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
| Result array | O(1) | O(n) | Constant time to instantiate array of length n O(1) | Array to store n elements  O(n) |
| Outer loop | O(n) | O(1) | Iteration over the list takes linear time O(n) | No additional memory is allocated O(1) |
| Inner loop | O(n<sup>2</sup>) | O(1) | For each element in the outer loop, iterates through all remaining elements O(n<sup>2</sup>) | No additional memory is allocated O(1) |
| Overall | O(n<sup>2</sup>) | O(1) | The nested loops result in O(n<sup>2</sup>) time complexity. Derivation of average case is found O(n<sup>2</sup>) is found [here](/blogs/common-formulas#brute-case-double-for-loop). | Memory allocation for array to store n result elements O(n) |


### Solution 1:  Prefix & Postfix 3 arrays O(n)
```python
    def productExceptSelf(self, nums: List[int]) -> List[int]:
        
        # space complexity: prefix, postfix, and result arrays to calculate and store final value for n integers O(n)
        prefix = [1] * len(nums)
        postfix = [1] * len(nums)
        res = [1] * len(nums)

        # Compute prefix products
        # time complexity: iteration over list of length n O(n)
        for i in range(1, len(nums)):
            
            # time complexity: lookup + multiplication operations take constant O(1)
            prefix[i] = prefix[i - 1] * nums[i - 1]

        # Compute postfix products
        # time complexity: iteration over list of length n O(n)
        for i in range(n - 2, -1, -1):

            # time complexity: lookup + multiplication operations take constant O(1)
            postfix[i] = postfix[i + 1] * nums[i + 1]

        # Combine prefix and postfix products
        # time complexity: iteration over list of length n O(n)
        for i in range(n):

            # time complexity: lookup + multiplication operations take constant O(1)
            res[i] = prefix[i] * postfix[i]


        # overall: time complexity
        # overall: space complexity 
        return res
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  | 
|  |  |  |  |  |


### Solution 2: Prefix & Postfix Optimal O(1) space

```python
    def productExceptSelf(self, nums: List[int]) -> List[int]:
        
        # instantiate to 1, start prefix calculation at res[1], prefix of res[0] is always 1
        # space complexity: array to store results for n integers O(n) 
        res = [1] * len(nums)

        # Compute prefix products in res
        # time complexity: iterate over list of size n O(n)
        for i in range(1, len(nums)):

            # time complexity:
            # (prefix of i) = (prefix of i - 1) * (num at i - 1)
            res[i] = res[i - 1] * nums[i - 1]

        # accumulate running postfix through iteration
        postfix = nums[len(nums)-1]

        # start at (n-1), start postfix calculation at res[n-2] (second to last index), postfix of res[n-1] (last index) is always 1
        # time complexity: iterate over list of size n in reverse O(n)
        for i in range(len(nums) - 2, -1, -1):
            
            # (product except i) = (prefix of i) * (postfix of i)
            res[i] *= postfix
            
            # (postfix of i - 1) = (postfix of i) * (num at i) 
            postfix *= nums[i]

        # overall: time complexity
        # overall: space complexity
        return res
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  | 
|  |  |  |  |  |


## 36. Valid Sudoku - Medium

### Intro
> Determine if a 9 x 9 Sudoku board is valid. Only the filled cells need to be validated according to the following rules:
> Each row must contain the digits 1-9 without repetition.
> Each column must contain the digits 1-9 without repetition.
> Each of the nine 3 x 3 sub-boxes of the grid must contain the digits 1-9 without repetition.

Constraints:

A Sudoku board (partially filled) could be valid but is not necessarily solvable.
Only the filled cells need to be validated according to the mentioned rules.


|  Input         | Output          |  
| -------------- | --------------- | 
| this is too big to put here lol | just look at -> [sudoku board example](https://leetcode.com/problems/valid-sudoku/description/) | 

### Abstraction
Here, we are looking for duplicates much like the original 217. Contains Duplicates.

The only difference here, is that we are looking for duplicates in 3 sets along the rows, columns, and 3x3 squares.

So we simply create sets for all of these groups and as we traverse the board, we check for duplicates

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
| Brute Force |  |  |  | |
| Hashmap |  |  |  |  |

### Solution 1: defaultdict()
```python 
    def isValidSudoku(self, board: List[List[str]]) -> bool:
        cols = defaultdict(set)
        rows = defaultdict(set)
        squares = defaultdict(set) # tuple key = (r /3, c /3)

        for r in range(9):
            for c in range(9):
                
                tmp = board[r][c]

                if tmp == ".":
                    continue
                
                if (tmp in rows[r] or 
                    tmp in cols[c] or 
                    tmp in squares[(r // 3, c // 3)] ):
                    return False
                
                cols[c].add(tmp)
                rows[r].add(tmp)
                squares[(r // 3, c // 3)].add(tmp)

        return True
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  | 
|  |  |  |  |  |

### Solution 2: Faster Manual []
```python
    def isValidSudoku(self, board: List[List[str]]) -> bool:
        rows = [[], [], [], [], [], [], [], [], []]
        col = [[], [], [], [], [], [], [], [], []]
        boxes = [[], [], [], [], [], [], [], [], []]

        for i in range(9):
            for j in range(9):
                tmp = board[i][j]
                if tmp != ".":    
                    box = 3 * (i//3) + (j//3)
                    if (tmp in rows[i] or 
                       tmp in col[j]  or 
                       tmp in boxes[box]):
                        return False

                    col[j].append(tmp)
                    rows[i].append(tmp)
                    boxes[box].append(tmp)

        return True
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  | 
|  |  |  |  |  |

Solution 2 ends up being faster than Solution 1:

While sets are generally more efficient for larger and more dynamic data due to constant-time 
lookups and insertions, for a fixed-size 9x9 board like this, the overhead introduced by defaultdict and 
set operations can make the list-based approach faster in practice. 


## 128. Longest Consecutive Sequence - Medium

### Intro
> Given an array of integers nums, return the length of the longest consecutive sequence of elements.
> A consecutive sequence is a sequence of elements in which each element is exactly 1 greater than 
> the previous element
> You must wrtie an algorithm that runs in O(n) time.

|  Input                    | Output  |  
| ------------------------- | ------- | 
| [2, 20, 4, 10, 3, 4, 5]   | 4       | 
| [0, 3, 2, 5, 4, 6, 1, 1]  | 7       |


Constraints:


### Abstraction
As usual, our goal is to translate this problem into something that is easier. 

A longest consecutive sequence on a number line would look like this:

[ 12, 1, 13, 0, 7, 2, 3, 11, 4] ---> 

| 0 1 2 3 4 |  ..... | 7 | ..... | 11 12 13 | 

Here, it is very simple to see what is the longest sequence.
Now the question is how to translate into this.
A set would be the easiest as we can simply check if some element exists 

### Space & Time Complexity
|  Solution  | Time Complexity | Space Complexity | Time Remark | Space Remark |  
| ---------- | --------------- | ---------------- | ----------- | ------------ |
| Brute Force |  |  |  | |
| Hashmap |  |  |  |  |

### Solution 1: Set abstraction
```python
def longestConsecutive(self, nums: List[int]) -> int: 
    numSet = set(nums)
    longest = 0
    for i in numSet:
        # found start of a sequence (left most element)
        if (i - 1) not in numSet: 
            currLen = 1
            while (i + currLen) in numSet:
                currLen += 1 
            longest = max(longest, currLen)

    return longest        
```

|  Aspect  | Time Complexity | Space Complexity |  Time Remarks | Space Remarks |
| -------- | --------------- | ---------------- | ------------- |  ------------ |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  | 
|  |  |  |  |  |